============================================================
ACTIVITY DETECTION ANALYSIS - COMPREHENSIVE PIPELINE
============================================================

Console output is being logged to: visualizations\console_output_20251205_142350.txt
============================================================

============================================================
TASK 1: Dataset Exploration
============================================================
Using local cache in C:\Users\joshd\school\cs156\CS156Project\data
Found 12 activity folders in local cache
Loading real data from activity folders...
Found 12 activity folders
Successfully loaded 12 activity sessions
Activity types found: {'walking', 'cycling', 'sitting'}

=== DATASET SUMMARY TABLE ===
                   Metric Value
   Number of Participants    12
Avg Files per Participant   1.0
  Total Labels/Activities    12
    Unique Activity Types     3
         Total Data Files    12

Activity types: ['cycling', 'sitting', 'walking']

[OK] Task 1 Complete: Dataset summary created

============================================================
TASK 2: Annotated Signal Exploration
============================================================

[OK] Task 2 Complete: Signal visualization finished

============================================================
TASK 3: Signal Preprocessing
============================================================
Missing data points: 3956
After preprocessing: 0
Original signal std: 51.9798
Preprocessed signal std: 0.0001

[OK] Task 3 Complete: Signal preprocessing finished

============================================================
TASK 4: Windowing Strategies
============================================================

=== WINDOWING ANALYSIS ===
 window_size  n_windows  coverage  time_duration_sec
          25       5986  1.041609                0.5
          50       2872  0.999680                1.0
          75       1940  1.013076                1.5
         100       1435  0.999332                2.0
         125       1157  1.007335                2.5
         150        956  0.998984                3.0
         175        824  1.004725                3.5
         200        717  0.999332                4.0
         250        573  0.998636                5.0
         300        477  0.997940                6.0
         400        358  0.999332                8.0
         500        286  0.998636               10.0

[OK] Task 4 Complete: Windowing analysis finished

============================================================
TASK 5: Feature Extraction & Analysis
============================================================
Extracting features from all data...
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups

Extracted 54688 feature vectors
Features: 201

=== TOP 15 MOST IMPORTANT FEATURES ===
                 feature  importance
               acc_y_zcr    0.015464
               acc_x_zcr    0.015191
               acc_z_zcr    0.015080
               gyr_x_zcr    0.014363
   gyr_x_spectral_energy    0.012405
 gyr_mag_spectral_energy    0.012181
   acc_z_spectral_energy    0.011898
               gyr_z_zcr    0.011784
acc_mag_spectral_rolloff    0.011340
               gyr_x_max    0.010951
 acc_mag_spectral_energy    0.010798
             acc_z_range    0.010687
      acc_z_peak_to_peak    0.010687
      gyr_x_peak_to_peak    0.010661
             gyr_x_range    0.010661

[OK] Task 5 Complete: Feature extraction finished

============================================================
TASK 6: Classical ML Modeling
============================================================
Training set size: 43750
Test set size: 10938
Number of classes: 3

Platform detected: Windows AMD64
Input features: 31, Number of classes: 3
Adjusted class weights (after overrides):
{np.int64(0): np.float64(0.5483693063598305), np.int64(1): np.float64(2.121632940969008), np.int64(2): np.float64(2.0518499218342887)}

Training Decision Tree...
  Accuracy: 0.6778
  Precision: 0.7435
  Recall: 0.7251
  F1-Score: 0.6849
  Training time: 0.41s
  Prediction time: 0.0010s

Training SVM...
  Accuracy: 0.6700
  Precision: 0.7119
  Recall: 0.7206
  F1-Score: 0.6729
  Training time: 2.31s
  Prediction time: 0.0010s

Training SVM (Calibrated)...
  Accuracy: 0.6847
  Precision: 0.7202
  Recall: 0.7201
  F1-Score: 0.6846
  Training time: 3.35s
  Prediction time: 0.0040s

Training Naive Bayes...
  Accuracy: 0.6269
  Precision: 0.6810
  Recall: 0.6867
  F1-Score: 0.6102
  Training time: 0.01s
  Prediction time: 0.0030s

Training Random Forest...
  Accuracy: 0.7022
  Precision: 0.7582
  Recall: 0.7485
  F1-Score: 0.7082
  Training time: 0.98s
  Prediction time: 0.0800s

Training Hist Gradient Boosting...
  Accuracy: 0.6942
  Precision: 0.7656
  Recall: 0.7479
  F1-Score: 0.7048
  Training time: 2.59s
  Prediction time: 0.0610s

Training SVM+HGB Ensemble...
  Accuracy: 0.6958
  Precision: 0.7434
  Recall: 0.7393
  F1-Score: 0.6997
  Training time: 4.99s
  Prediction time: 0.0670s

Training AdaBoost...
  Accuracy: 0.5005
  Precision: 0.6977
  Recall: 0.6291
  F1-Score: 0.5511
  Training time: 3.65s
  Prediction time: 0.0260s

Training XGBoost...
  Accuracy: 0.7068
  Precision: 0.7644
  Recall: 0.7522
  F1-Score: 0.7125
  Training time: 1.71s
  Prediction time: 0.0120s

=== MODEL COMPARISON SUMMARY ===
                 Model  Accuracy  Precision   Recall  F1-Score  Train Time (s)  Pred Time (s)
         Decision Tree  0.677820   0.743507 0.725126  0.684852        0.406538       0.001000
                   SVM  0.669958   0.711853 0.720568  0.672858        2.306324       0.000998
      SVM (Calibrated)  0.684677   0.720186 0.720057  0.684606        3.354738       0.004000
           Naive Bayes  0.626897   0.681011 0.686666  0.610177        0.014999       0.003001
         Random Forest  0.702231   0.758163 0.748516  0.708176        0.984219       0.080001
Hist Gradient Boosting  0.694185   0.765564 0.747918  0.704768        2.585499       0.061000
      SVM+HGB Ensemble  0.695831   0.743397 0.739309  0.699726        4.992877       0.066997
              AdaBoost  0.500457   0.697672 0.629064  0.551114        3.646911       0.026000
               XGBoost  0.706802   0.764429 0.752182  0.712453        1.712612       0.011999

Best model (by macro F1-Score): XGBoost

[OK] Task 6 Complete: Classical ML modeling finished

============================================================
TASK 7: Advanced Evaluation
============================================================

Number of unique participants: 12
Participants: ['Cycling-2023-09-14_06-22-31' 'Cycling-2023-09-14_06-33-47'
 'Cycling-2023-09-14_06-47-00' 'Cycling-2023-09-16_07-43-07'
 'Cycling-2023-09-16_09-25-09' 'Cycling-2023-10-18_06-36-17'
 'Cycling-2023-10-18_06-51-26' 'Sitting-2023-09-14_08-37-45'
 'Sitting-2023-09-14_09-11-15' 'Sitting-2023-10-18_09-05-37'
 'Walking-2023-09-14_21-51-59' 'Walking-2023-09-16_18-14-40']
Using scikit-learn XGBClassifier
Running LOSO evaluation (may take a while)...

Fold 1/12 (Participant Cycling-2023-09-14_06-22-31): Accuracy = 0.9371
Fold 2/12 (Participant Cycling-2023-09-14_06-33-47): Accuracy = 0.9323
Fold 3/12 (Participant Cycling-2023-09-14_06-47-00): Accuracy = 0.9830
Fold 4/12 (Participant Cycling-2023-09-16_07-43-07): Accuracy = 0.9160
Fold 5/12 (Participant Cycling-2023-09-16_09-25-09): Accuracy = 0.9781
Fold 6/12 (Participant Cycling-2023-10-18_06-36-17): Accuracy = 0.9518
Fold 7/12 (Participant Cycling-2023-10-18_06-51-26): Accuracy = 0.9498
Fold 8/12 (Participant Sitting-2023-09-14_08-37-45): Accuracy = 0.6240
Fold 9/12 (Participant Sitting-2023-09-14_09-11-15): Accuracy = 0.5812
Fold 10/12 (Participant Sitting-2023-10-18_09-05-37): Accuracy = 0.6926
Fold 11/12 (Participant Walking-2023-09-14_21-51-59): Accuracy = 0.6286
Fold 12/12 (Participant Walking-2023-09-16_18-14-40): Accuracy = 0.4093

=== LOSO OVERALL RESULTS ===
Mean Accuracy: 0.7986 (+/- 0.1899)
Overall Accuracy: 0.7837
Overall Precision (macro): 0.8067
Overall Recall (macro): 0.6730
Overall F1-Score (macro): 0.7148

=== EVALUATION METHOD COMPARISON ===
     Evaluation Method  Accuracy  Precision (macro)  Recall (macro)  F1-Score (macro)
Standard Split (80/20)  0.706802           0.764429        0.752182          0.712453
 LOSO Cross-Validation  0.783719           0.806655        0.673015          0.714838
Testing window size: 25 samples (0.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6586, F1: 0.6666, N=684178

Testing window size: 50 samples (1.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6756, F1: 0.6817, N=328375

Testing window size: 75 samples (1.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6841, F1: 0.6908, N=221854

Testing window size: 100 samples (2.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6860, F1: 0.6931, N=164167

Testing window size: 125 samples (2.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6795, F1: 0.6880, N=132376

Testing window size: 150 samples (3.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6896, F1: 0.6953, N=109423

Testing window size: 175 samples (3.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6903, F1: 0.6954, N=94327

Testing window size: 200 samples (4.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.8240, F1: 0.7736, N=82063

Testing window size: 250 samples (5.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6982, F1: 0.7015, N=65632

Testing window size: 300 samples (6.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.8341, F1: 0.7868, N=54688


=== WINDOW SIZE COMPARISON TABLE ===
 Window Size  Duration (s)  N Samples  Accuracy  Precision   Recall  F1-Score
          25           0.5     684178  0.658577   0.715846 0.694727  0.666636
          50           1.0     328375  0.675615   0.730907 0.711956  0.681706
          75           1.5     221854  0.684073   0.738890 0.722159  0.690818
         100           2.0     164167  0.686027   0.742301 0.724603  0.693081
         125           2.5     132376  0.679483   0.740665 0.720807  0.687956
         150           3.0     109423  0.689605   0.749483 0.726518  0.695327
         175           3.5      94327  0.690342   0.744506 0.728733  0.695445
         200           4.0      82063  0.824042   0.857469 0.731848  0.773618
         250           5.0      65632  0.698179   0.748769 0.734261  0.701462
         300           6.0      54688  0.834065   0.871198 0.743708  0.786761

=== PER-CLASS PERFORMANCE REPORT ===
              precision    recall  f1-score   support

     cycling       0.97      0.63      0.76      6649
     sitting       0.89      0.70      0.78      1890
     walking       0.43      0.93      0.59      2399

    accuracy                           0.71     10938
   macro avg       0.76      0.75      0.71     10938
weighted avg       0.84      0.71      0.73     10938


Most common classification errors (true -> predicted):
  true=cycling, predicted=walking: 2369 times
  true=sitting, predicted=walking: 550 times
  true=walking, predicted=cycling: 109 times
  true=cycling, predicted=sitting: 96 times
  true=walking, predicted=sitting: 68 times
  true=sitting, predicted=cycling: 15 times

[OK] Task 7 Complete: Advanced evaluation finished

============================================================
DEEP LEARNING PREPARATION: Sequences for ANN Models
============================================================

============================================================
PREPARING SEQUENCES FOR ANN MODELS
============================================================
Creating sequences from preprocessed sensor data...
Found 7 unique sensor channels across all participants
Created 18489 sequences with shape (18489, 300, 7)
Created 18489 sequences
Sequence shape: (18489, 300, 7) (n_samples, window_size=300, n_features=7)
Number of features per timestep: 7
Classes: ['cycling' 'sitting' 'walking']

Train set: 16462 sequences from 9 participants
Test set: 2027 sequences from 3 participants

Saved sequences to:
  - data\processed\X_seq_train.npy
  - data\processed\X_seq_test.npy
  - data\processed\y_seq_train.npy
  - data\processed\y_seq_test.npy

Normalization: standardize
  Normalized 7 feature channels independently

[OK] Sequence preparation for ANN models complete

[OK] Deep Learning preparation complete: Sequences formatted for ANN models

============================================================
ALL TASKS COMPLETE!
============================================================

Visualizations saved to: visualizations

Generated files:
  - task1_dataset_exploration.png
  - task2_annotated_signals.png
  - task3_preprocessing_comparison.png
  - task4_windowing_strategies.png
  - task5_feature_distributions.png
  - task5_feature_importance.png
  - task6_model_comparison.png
  - task7_evaluation_comparison.png
  - task7_window_size_comparison.png
  - task7_confusion_matrix.png
  - task7_error_analysis.png
  - data/processed/X_seq_train.npy, data/processed/X_seq_test.npy (sequence data for deep activity classification models)
  - data/processed/y_seq_train.npy, data/processed/y_seq_test.npy (sequence labels for activity classification)
  - console_output_20251205_142350.txt (console output log)
============================================================
