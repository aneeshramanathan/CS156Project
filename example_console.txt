============================================================
ACTIVITY DETECTION ANALYSIS - COMPREHENSIVE PIPELINE
============================================================

Console output is being logged to: visualizations\console_output_20251117_223555.txt
============================================================

============================================================
TASK 1: Dataset Exploration
============================================================
Using local cache in C:\Users\joshd\school\cs156\CS156Project\data
Found 12 activity folders in local cache
Loading real data from activity folders...
Found 12 activity folders
Successfully loaded 12 activity sessions
Activity types found: {'cycling', 'walking', 'sitting'}

=== DATASET SUMMARY TABLE ===
                   Metric Value
   Number of Participants    12
Avg Files per Participant   1.0
  Total Labels/Activities    12
    Unique Activity Types     3
         Total Data Files    12

Activity types: ['cycling', 'sitting', 'walking']

[OK] Task 1 Complete: Dataset summary created

============================================================
TASK 2: Annotated Signal Exploration
============================================================

[OK] Task 2 Complete: Signal visualization finished

============================================================
TASK 3: Signal Preprocessing
============================================================
Missing data points: 3963
After preprocessing: 0
Original signal std: 51.9722
Preprocessed signal std: 0.0001

[OK] Task 3 Complete: Signal preprocessing finished

============================================================
TASK 4: Windowing Strategies
============================================================

=== WINDOWING ANALYSIS ===
 window_size  n_windows  coverage  time_duration_sec
          25       5986  1.041609                0.5
          50       2872  0.999680                1.0
          75       1940  1.013076                1.5
         100       1435  0.999332                2.0
         125       1157  1.007335                2.5
         150        956  0.998984                3.0
         175        824  1.004725                3.5
         200        717  0.999332                4.0
         250        573  0.998636                5.0
         300        477  0.997940                6.0
         400        358  0.999332                8.0
         500        286  0.998636               10.0

[OK] Task 4 Complete: Windowing analysis finished

============================================================
TASK 5: Feature Extraction & Analysis
============================================================
Extracting features from all data...
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups

Extracted 54688 feature vectors
Features: 201

=== TOP 15 MOST IMPORTANT FEATURES ===
                 feature  importance
               acc_y_zcr    0.015464
               acc_x_zcr    0.015191
               acc_z_zcr    0.015080
               gyr_x_zcr    0.014363
   gyr_x_spectral_energy    0.012405
 gyr_mag_spectral_energy    0.012181
   acc_z_spectral_energy    0.011898
               gyr_z_zcr    0.011784
acc_mag_spectral_rolloff    0.011340
               gyr_x_max    0.010951
 acc_mag_spectral_energy    0.010798
             acc_z_range    0.010687
      acc_z_peak_to_peak    0.010687
      gyr_x_peak_to_peak    0.010661
             gyr_x_range    0.010661

[OK] Task 5 Complete: Feature extraction finished

============================================================
TASK 6: Classical ML Modeling
============================================================
Training set size: 43750
Test set size: 10938
Number of classes: 3

Platform detected: Windows AMD64
Using CPU-based scikit-learn models for classical ML algorithms
Input features: 31, Number of classes: 3
Adjusted class weights (after overrides):
{np.int64(0): np.float64(0.5483693063598305), np.int64(1): np.float64(2.121632940969008), np.int64(2): np.float64(2.0518499218342887)}

Training Decision Tree...
  Accuracy: 0.6710
  Precision: 0.7426
  Recall: 0.7183
  F1-Score: 0.6799
  Training time: 0.41s
  Prediction time: 0.0010s

Training SVM...
  Accuracy: 0.6696
  Precision: 0.7101
  Recall: 0.7204
  F1-Score: 0.6723
  Training time: 1.96s
  Prediction time: 0.0010s

Training SVM (Calibrated)...
  Accuracy: 0.6847
  Precision: 0.7197
  Recall: 0.7202
  F1-Score: 0.6847
  Training time: 4.03s
  Prediction time: 0.0040s

Training Naive Bayes...
  Accuracy: 0.6274
  Precision: 0.6820
  Recall: 0.6867
  F1-Score: 0.6107
  Training time: 0.02s
  Prediction time: 0.0030s

Training Random Forest...
  Accuracy: 0.7019
  Precision: 0.7581
  Recall: 0.7476
  F1-Score: 0.7078
  Training time: 0.97s
  Prediction time: 0.0735s

Training Hist Gradient Boosting...
  Accuracy: 0.6946
  Precision: 0.7648
  Recall: 0.7486
  F1-Score: 0.7049
  Training time: 2.56s
  Prediction time: 0.0580s

Training SVM+HGB Ensemble...
  Accuracy: 0.6947
  Precision: 0.7427
  Recall: 0.7380
  F1-Score: 0.6989
  Training time: 5.07s
  Prediction time: 0.0680s

Training AdaBoost...
  Accuracy: 0.5031
  Precision: 0.6999
  Recall: 0.6299
  F1-Score: 0.5538
  Training time: 3.63s
  Prediction time: 0.0260s

Training XGBoost (true gradient-boosted trees)...
  Accuracy: 0.7042
  Precision: 0.7630
  Recall: 0.7491
  F1-Score: 0.7101
  Training time: 1.57s
  Prediction time: 0.0120s

=== MODEL COMPARISON SUMMARY ===
                 Model  Accuracy  Precision   Recall  F1-Score  Train Time (s)  Pred Time (s)
         Decision Tree  0.670964   0.742579 0.718252  0.679908        0.407000       0.001000
                   SVM  0.669592   0.710103 0.720354  0.672314        1.962322       0.001001
      SVM (Calibrated)  0.684677   0.719692 0.720221  0.684664        4.032384       0.004001
           Naive Bayes  0.627354   0.682018 0.686664  0.610655        0.015000       0.003000
         Random Forest  0.701865   0.758052 0.747595  0.707780        0.970516       0.073520
Hist Gradient Boosting  0.694551   0.764781 0.748624  0.704912        2.558032       0.058000
      SVM+HGB Ensemble  0.694734   0.742697 0.738010  0.698851        5.069849       0.067998
              AdaBoost  0.503108   0.699875 0.629873  0.553823        3.634686       0.026000
               XGBoost  0.704151   0.762964 0.749068  0.710144        1.568123       0.012001

Best model (by macro F1-Score): XGBoost

[OK] Task 6 Complete: Classical ML modeling finished

============================================================
TASK 7: Advanced Evaluation
============================================================

Number of unique participants: 12
Participants: ['Cycling-2023-09-14_06-22-31' 'Cycling-2023-09-14_06-33-47'
 'Cycling-2023-09-14_06-47-00' 'Cycling-2023-09-16_07-43-07'
 'Cycling-2023-09-16_09-25-09' 'Cycling-2023-10-18_06-36-17'
 'Cycling-2023-10-18_06-51-26' 'Sitting-2023-09-14_08-37-45'
 'Sitting-2023-09-14_09-11-15' 'Sitting-2023-10-18_09-05-37'
 'Walking-2023-09-14_21-51-59' 'Walking-2023-09-16_18-14-40']
Using scikit-learn XGBClassifier
Running LOSO evaluation (may take a while)...

Fold 1/12 (Participant Cycling-2023-09-14_06-22-31): Accuracy = 0.9336
Fold 2/12 (Participant Cycling-2023-09-14_06-33-47): Accuracy = 0.9332
Fold 3/12 (Participant Cycling-2023-09-14_06-47-00): Accuracy = 0.9834
Fold 4/12 (Participant Cycling-2023-09-16_07-43-07): Accuracy = 0.9159
Fold 5/12 (Participant Cycling-2023-09-16_09-25-09): Accuracy = 0.9779
Fold 6/12 (Participant Cycling-2023-10-18_06-36-17): Accuracy = 0.9542
Fold 7/12 (Participant Cycling-2023-10-18_06-51-26): Accuracy = 0.9483
Fold 8/12 (Participant Sitting-2023-09-14_08-37-45): Accuracy = 0.6251
Fold 9/12 (Participant Sitting-2023-09-14_09-11-15): Accuracy = 0.5769
Fold 10/12 (Participant Sitting-2023-10-18_09-05-37): Accuracy = 0.6996
Fold 11/12 (Participant Walking-2023-09-14_21-51-59): Accuracy = 0.6286
Fold 12/12 (Participant Walking-2023-09-16_18-14-40): Accuracy = 0.4100

=== LOSO OVERALL RESULTS ===
Mean Accuracy: 0.7989 (+/- 0.1897)
Overall Accuracy: 0.7838
Overall Precision (macro): 0.8068
Overall Recall (macro): 0.6731
Overall F1-Score (macro): 0.7150

=== EVALUATION METHOD COMPARISON ===
     Evaluation Method  Accuracy  Precision (macro)  Recall (macro)  F1-Score (macro)
Standard Split (80/20)  0.704151           0.762964        0.749068          0.710144
 LOSO Cross-Validation  0.783828           0.806781        0.673123          0.714975
Testing window size: 25 samples (0.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6584, F1: 0.6665, N=684178

Testing window size: 50 samples (1.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6750, F1: 0.6808, N=328375

Testing window size: 75 samples (1.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6847, F1: 0.6912, N=221854

Testing window size: 100 samples (2.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6854, F1: 0.6923, N=164167

Testing window size: 125 samples (2.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6792, F1: 0.6880, N=132376

Testing window size: 150 samples (3.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6885, F1: 0.6939, N=109423

Testing window size: 175 samples (3.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6906, F1: 0.6954, N=94327

Testing window size: 200 samples (4.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6934, F1: 0.6982, N=82063

Testing window size: 250 samples (5.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6974, F1: 0.7013, N=65632

Testing window size: 300 samples (6.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.8396, F1: 0.7935, N=54688


=== WINDOW SIZE COMPARISON TABLE ===
 Window Size  Duration (s)  N Samples  Accuracy  Precision   Recall  F1-Score
          25           0.5     684178  0.658423   0.715546 0.694474  0.666520
          50           1.0     328375  0.675006   0.729373 0.710506  0.680772
          75           1.5     221854  0.684681   0.739088 0.722565  0.691158
         100           2.0     164167  0.685448   0.743142 0.723460  0.692274
         125           2.5     132376  0.679181   0.740944 0.720719  0.688023
         150           3.0     109423  0.688508   0.747297 0.725734  0.693878
         175           3.5      94327  0.690554   0.744346 0.728578  0.695441
         200           4.0      82063  0.693353   0.746943 0.731215  0.698225
         250           5.0      65632  0.697418   0.748666 0.734042  0.701294
         300           6.0      54688  0.839550   0.878090 0.749412  0.793490

=== PER-CLASS PERFORMANCE REPORT ===
              precision    recall  f1-score   support

     cycling       0.97      0.63      0.76      6649
     sitting       0.89      0.70      0.78      1890
     walking       0.43      0.92      0.59      2399

    accuracy                           0.70     10938
   macro avg       0.76      0.75      0.71     10938
weighted avg       0.84      0.70      0.73     10938


Most common classification errors (true -> predicted):
  true=cycling, predicted=walking: 2388 times
  true=sitting, predicted=walking: 551 times
  true=walking, predicted=cycling: 118 times
  true=cycling, predicted=sitting: 89 times
  true=walking, predicted=sitting: 72 times
  true=sitting, predicted=cycling: 18 times

[OK] Task 7 Complete: Advanced evaluation finished

============================================================
ALL TASKS COMPLETE!
============================================================

Visualizations saved to: visualizations

Generated files:
  - task1_dataset_exploration.png
  - task2_annotated_signals.png
  - task3_preprocessing_comparison.png
  - task4_windowing_strategies.png
  - task5_feature_distributions.png
  - task5_feature_importance.png
  - task6_model_comparison.png
  - task7_evaluation_comparison.png
  - task7_window_size_comparison.png
  - task7_confusion_matrix.png
  - task7_error_analysis.png
  - data/processed/X_seq_train.npy, data/processed/X_seq_test.npy (sequence data for deep activity classification models)
  - data/processed/y_seq_train.npy, data/processed/y_seq_test.npy (sequence labels for activity classification)
  - console_output_20251117_223555.txt (console output log)
============================================================
