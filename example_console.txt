============================================================
ACTIVITY DETECTION ANALYSIS - COMPREHENSIVE PIPELINE
============================================================

Console output is being logged to: visualizations\console_output_20251205_193840.txt
============================================================

============================================================
TASK 1: Dataset Exploration
============================================================
Using local cache in C:\Users\joshd\school\cs156\CS156Project\data
Found 12 activity folders in local cache
Loading real data from activity folders...
Found 12 activity folders
Successfully loaded 12 activity sessions
Activity types found: {'sitting', 'walking', 'cycling'}

=== DATASET SUMMARY TABLE ===
                   Metric Value
   Number of Participants    12
Avg Files per Participant   1.0
  Total Labels/Activities    12
    Unique Activity Types     3
         Total Data Files    12

Activity types: ['cycling', 'sitting', 'walking']

[OK] Task 1 Complete: Dataset summary created

============================================================
TASK 2: Annotated Signal Exploration
============================================================

[OK] Task 2 Complete: Signal visualization finished

============================================================
TASK 3: Signal Preprocessing
============================================================
Missing data points: 3964
After preprocessing: 0
Original signal std: 51.9498
Preprocessed signal std: 0.0001

[OK] Task 3 Complete: Signal preprocessing finished

============================================================
TASK 4: Windowing Strategies
============================================================

=== WINDOWING ANALYSIS ===
 window_size  n_windows  coverage  time_duration_sec
          25       5986  1.041609                0.5
          50       2872  0.999680                1.0
          75       1940  1.013076                1.5
         100       1435  0.999332                2.0
         125       1157  1.007335                2.5
         150        956  0.998984                3.0
         175        824  1.004725                3.5
         200        717  0.999332                4.0
         250        573  0.998636                5.0
         300        477  0.997940                6.0
         400        358  0.999332                8.0
         500        286  0.998636               10.0

[OK] Task 4 Complete: Windowing analysis finished

============================================================
TASK 5: Feature Extraction & Analysis
============================================================
Extracting features from all data...
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups

Extracted 54688 feature vectors
Features: 201

=== TOP 15 MOST IMPORTANT FEATURES ===
                 feature  importance
               acc_y_zcr    0.015464
               acc_x_zcr    0.015191
               acc_z_zcr    0.015080
               gyr_x_zcr    0.014363
   gyr_x_spectral_energy    0.012405
 gyr_mag_spectral_energy    0.012181
   acc_z_spectral_energy    0.011898
               gyr_z_zcr    0.011784
acc_mag_spectral_rolloff    0.011340
               gyr_x_max    0.010951
 acc_mag_spectral_energy    0.010798
             acc_z_range    0.010687
      acc_z_peak_to_peak    0.010687
      gyr_x_peak_to_peak    0.010661
             gyr_x_range    0.010661

[OK] Task 5 Complete: Feature extraction finished

============================================================
TASK 6: Classical ML Modeling
============================================================
Training set size: 43750
Test set size: 10938
Number of classes: 3

Platform detected: Windows AMD64
Input features: 31, Number of classes: 3
Adjusted class weights (after overrides):
{np.int64(0): np.float64(0.5483693063598305), np.int64(1): np.float64(2.121632940969008), np.int64(2): np.float64(2.0518499218342887)}

Training Decision Tree...
  Accuracy: 0.6816
  Precision: 0.7471
  Recall: 0.7272
  F1-Score: 0.6883
  Training time: 0.39s
  Prediction time: 0.0010s

Training SVM...
  Accuracy: 0.6672
  Precision: 0.7102
  Recall: 0.7197
  F1-Score: 0.6710
  Training time: 1.83s
  Prediction time: 0.0010s

Training SVM (Calibrated)...
  Accuracy: 0.6850
  Precision: 0.7206
  Recall: 0.7211
  F1-Score: 0.6853
  Training time: 3.28s
  Prediction time: 0.0040s

Training Naive Bayes...
  Accuracy: 0.6260
  Precision: 0.6807
  Recall: 0.6862
  F1-Score: 0.6095
  Training time: 0.01s
  Prediction time: 0.0020s

Training Random Forest...
  Accuracy: 0.7026
  Precision: 0.7567
  Recall: 0.7489
  F1-Score: 0.7083
  Training time: 0.98s
  Prediction time: 0.0740s

Training Hist Gradient Boosting...
  Accuracy: 0.6946
  Precision: 0.7624
  Recall: 0.7489
  F1-Score: 0.7043
  Training time: 2.63s
  Prediction time: 0.0590s

Training SVM+HGB Ensemble...
  Accuracy: 0.6964
  Precision: 0.7434
  Recall: 0.7401
  F1-Score: 0.7004
  Training time: 4.95s
  Prediction time: 0.0670s

Training AdaBoost...
  Accuracy: 0.6725
  Precision: 0.7290
  Recall: 0.7114
  F1-Score: 0.6755
  Training time: 3.68s
  Prediction time: 0.0270s

Training XGBoost...
  Accuracy: 0.7065
  Precision: 0.7655
  Recall: 0.7515
  F1-Score: 0.7126
  Training time: 1.63s
  Prediction time: 0.0130s

=== MODEL COMPARISON SUMMARY ===
                 Model  Accuracy  Precision   Recall  F1-Score  Train Time (s)  Pred Time (s)
         Decision Tree  0.681569   0.747080 0.727167  0.688324        0.395000       0.001000
                   SVM  0.667215   0.710203 0.719695  0.670975        1.825247       0.001001
      SVM (Calibrated)  0.685043   0.720557 0.721066  0.685319        3.283767       0.004000
           Naive Bayes  0.625983   0.680745 0.686165  0.609534        0.014003       0.001998
         Random Forest  0.702596   0.756699 0.748866  0.708266        0.981279       0.074000
Hist Gradient Boosting  0.694551   0.762410 0.748876  0.704343        2.633646       0.059001
      SVM+HGB Ensemble  0.696380   0.743364 0.740114  0.700391        4.954676       0.066999
              AdaBoost  0.672518   0.728985 0.711424  0.675473        3.676486       0.027000
               XGBoost  0.706528   0.765541 0.751498  0.712586        1.632537       0.013002

Best model (by macro F1-Score): XGBoost

[OK] Task 6 Complete: Classical ML modeling finished

============================================================
TASK 7: Advanced Evaluation
============================================================

Number of unique participants: 12
Participants: ['Cycling-2023-09-14_06-22-31' 'Cycling-2023-09-14_06-33-47'
 'Cycling-2023-09-14_06-47-00' 'Cycling-2023-09-16_07-43-07'
 'Cycling-2023-09-16_09-25-09' 'Cycling-2023-10-18_06-36-17'
 'Cycling-2023-10-18_06-51-26' 'Sitting-2023-09-14_08-37-45'
 'Sitting-2023-09-14_09-11-15' 'Sitting-2023-10-18_09-05-37'
 'Walking-2023-09-14_21-51-59' 'Walking-2023-09-16_18-14-40']
Using scikit-learn XGBClassifier
Running LOSO evaluation (may take a while)...

Fold 1/12 (Participant Cycling-2023-09-14_06-22-31): Accuracy = 0.9364
Fold 2/12 (Participant Cycling-2023-09-14_06-33-47): Accuracy = 0.9329
Fold 3/12 (Participant Cycling-2023-09-14_06-47-00): Accuracy = 0.9844
Fold 4/12 (Participant Cycling-2023-09-16_07-43-07): Accuracy = 0.9151
Fold 5/12 (Participant Cycling-2023-09-16_09-25-09): Accuracy = 0.9779
Fold 6/12 (Participant Cycling-2023-10-18_06-36-17): Accuracy = 0.9544
Fold 7/12 (Participant Cycling-2023-10-18_06-51-26): Accuracy = 0.9483
Fold 8/12 (Participant Sitting-2023-09-14_08-37-45): Accuracy = 0.6262
Fold 9/12 (Participant Sitting-2023-09-14_09-11-15): Accuracy = 0.5790
Fold 10/12 (Participant Sitting-2023-10-18_09-05-37): Accuracy = 0.6938
Fold 11/12 (Participant Walking-2023-09-14_21-51-59): Accuracy = 0.6291
Fold 12/12 (Participant Walking-2023-09-16_18-14-40): Accuracy = 0.4096

=== LOSO OVERALL RESULTS ===
Mean Accuracy: 0.7989 (+/- 0.1900)
Overall Accuracy: 0.7839
Overall Precision (macro): 0.8069
Overall Recall (macro): 0.6732
Overall F1-Score (macro): 0.7150

=== EVALUATION METHOD COMPARISON ===
     Evaluation Method  Accuracy  Precision (macro)  Recall (macro)  F1-Score (macro)
Standard Split (80/20)  0.706528           0.765541        0.751498          0.712586
 LOSO Cross-Validation  0.783865           0.806877        0.673191          0.715009
Testing window size: 25 samples (0.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6578, F1: 0.6661, N=684178

Testing window size: 50 samples (1.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6753, F1: 0.6812, N=328375

Testing window size: 75 samples (1.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6844, F1: 0.6908, N=221854

Testing window size: 100 samples (2.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6860, F1: 0.6932, N=164167

Testing window size: 125 samples (2.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6799, F1: 0.6880, N=132376

Testing window size: 150 samples (3.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6900, F1: 0.6952, N=109423

Testing window size: 175 samples (3.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6900, F1: 0.6952, N=94327

Testing window size: 200 samples (4.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.8261, F1: 0.7765, N=82063

Testing window size: 250 samples (5.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.6999, F1: 0.7037, N=65632

Testing window size: 300 samples (6.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...  Processed 20/35 sensor groups...  Processed 30/35 sensor groups...  Processed 35/35 sensor groups...
  Completed processing all 35 sensor groups
  Accuracy: 0.8358, F1: 0.7887, N=54688


=== WINDOW SIZE COMPARISON TABLE ===
 Window Size  Duration (s)  N Samples  Accuracy  Precision   Recall  F1-Score
          25           0.5     684178  0.657817   0.715274 0.694111  0.666055
          50           1.0     328375  0.675341   0.730270 0.711046  0.681198
          75           1.5     221854  0.684434   0.738804 0.722233  0.690816
         100           2.0     164167  0.685966   0.742738 0.724515  0.693215
         125           2.5     132376  0.679937   0.740394 0.720768  0.688035
         150           3.0     109423  0.689970   0.749046 0.726181  0.695164
         175           3.5      94327  0.689971   0.744981 0.727229  0.695152
         200           4.0      82063  0.826113   0.862753 0.733426  0.776478
         250           5.0      65632  0.699855   0.751368 0.736478  0.703704
         300           6.0      54688  0.835802   0.874367 0.745230  0.788678

=== PER-CLASS PERFORMANCE REPORT ===
              precision    recall  f1-score   support

     cycling       0.97      0.63      0.76      6649
     sitting       0.90      0.70      0.79      1890
     walking       0.43      0.92      0.59      2399

    accuracy                           0.71     10938
   macro avg       0.77      0.75      0.71     10938
weighted avg       0.84      0.71      0.73     10938


Most common classification errors (true -> predicted):
  true=cycling, predicted=walking: 2376 times
  true=sitting, predicted=walking: 552 times
  true=walking, predicted=cycling: 114 times
  true=cycling, predicted=sitting: 86 times
  true=walking, predicted=sitting: 69 times
  true=sitting, predicted=cycling: 13 times

[OK] Task 7 Complete: Advanced evaluation finished

============================================================
DEEP LEARNING PREPARATION: Sequences for ANN Models
============================================================

============================================================
PREPARING SEQUENCES FOR ANN MODELS
============================================================
Creating sequences from preprocessed sensor data...
Found 7 unique sensor channels across all participants
Created 18489 sequences with shape (18489, 300, 7)
Created 18489 sequences
Sequence shape: (18489, 300, 7) (n_samples, window_size=300, n_features=7)
Number of features per timestep: 7
Classes: ['cycling' 'sitting' 'walking']

Train set: 16462 sequences from 9 participants
Test set: 2027 sequences from 3 participants

Saved sequences to:
  - data\processed\X_seq_train.npy
  - data\processed\X_seq_test.npy
  - data\processed\y_seq_train.npy
  - data\processed\y_seq_test.npy

Normalization: standardize
  Normalized 7 feature channels independently

[OK] Sequence preparation for ANN models complete

[OK] Deep Learning preparation complete: Sequences formatted for ANN models

============================================================
ALL TASKS COMPLETE!
============================================================

Visualizations saved to: visualizations

Generated files:
  - task1_dataset_exploration.png
  - task2_annotated_signals.png
  - task3_preprocessing_comparison.png
  - task4_windowing_strategies.png
  - task5_feature_distributions.png
  - task5_feature_importance.png
  - task6_model_comparison.png
  - task7_evaluation_comparison.png
  - task7_window_size_comparison.png
  - task7_confusion_matrix.png
  - task7_error_analysis.png
  - data/processed/X_seq_train.npy, data/processed/X_seq_test.npy (sequence data for deep activity classification models)
  - data/processed/y_seq_train.npy, data/processed/y_seq_test.npy (sequence labels for activity classification)
  - console_output_20251205_193840.txt (console output log)
============================================================
