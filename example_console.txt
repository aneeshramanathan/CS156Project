============================================================
ACTIVITY DETECTION ANALYSIS - COMPREHENSIVE PIPELINE
============================================================

Console output is being logged to: visualizations\console_output_20251117_231050.txt
============================================================

============================================================
TASK 1: Dataset Exploration
============================================================
Using local cache in C:\Users\joshd\school\cs156\CS156Project\data
Found 12 activity folders in local cache
Loading real data from activity folders...
Found 12 activity folders
Successfully loaded 12 activity sessions
Activity types found: {'sitting', 'cycling', 'walking'}

=== DATASET SUMMARY TABLE ===
                   Metric Value
   Number of Participants    12
Avg Files per Participant   1.0
  Total Labels/Activities    12
    Unique Activity Types     3
         Total Data Files    12

Activity types: ['cycling', 'sitting', 'walking']

[OK] Task 1 Complete: Dataset summary created

============================================================
TASK 2: Annotated Signal Exploration
============================================================

[OK] Task 2 Complete: Signal visualization finished

============================================================
TASK 3: Signal Preprocessing
============================================================
Missing data points: 3962
After preprocessing: 0
Original signal std: 51.9647
Preprocessed signal std: 0.0001

[OK] Task 3 Complete: Signal preprocessing finished

============================================================
TASK 4: Windowing Strategies
============================================================

=== WINDOWING ANALYSIS ===
 window_size  n_windows  coverage  time_duration_sec
          25       5986  1.041609                0.5
          50       2872  0.999680                1.0
          75       1940  1.013076                1.5
         100       1435  0.999332                2.0
         125       1157  1.007335                2.5
         150        956  0.998984                3.0
         175        824  1.004725                3.5
         200        717  0.999332                4.0
         250        573  0.998636                5.0
         300        477  0.997940                6.0
         400        358  0.999332                8.0
         500        286  0.998636               10.0

[OK] Task 4 Complete: Windowing analysis finished

============================================================
TASK 5: Feature Extraction & Analysis
============================================================
Extracting features from all data...
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups

Extracted 54688 feature vectors
Features: 201

=== TOP 15 MOST IMPORTANT FEATURES ===
                 feature  importance
               acc_y_zcr    0.015464
               acc_x_zcr    0.015191
               acc_z_zcr    0.015080
               gyr_x_zcr    0.014363
   gyr_x_spectral_energy    0.012405
 gyr_mag_spectral_energy    0.012181
   acc_z_spectral_energy    0.011898
               gyr_z_zcr    0.011784
acc_mag_spectral_rolloff    0.011340
               gyr_x_max    0.010951
 acc_mag_spectral_energy    0.010798
             acc_z_range    0.010687
      acc_z_peak_to_peak    0.010687
      gyr_x_peak_to_peak    0.010661
             gyr_x_range    0.010661

[OK] Task 5 Complete: Feature extraction finished

============================================================
TASK 6: Classical ML Modeling
============================================================
Training set size: 43750
Test set size: 10938
Number of classes: 3

Platform detected: Windows AMD64
Input features: 31, Number of classes: 3
Adjusted class weights (after overrides):
{np.int64(0): np.float64(0.5483693063598305), np.int64(1): np.float64(2.121632940969008), np.int64(2): np.float64(2.0518499218342887)}

Training Decision Tree...
  Accuracy: 0.6757
  Precision: 0.7441
  Recall: 0.7221
  F1-Score: 0.6828
  Training time: 0.39s
  Prediction time: 0.0010s

Training SVM...
  Accuracy: 0.6702
  Precision: 0.7121
  Recall: 0.7205
  F1-Score: 0.6732
  Training time: 2.08s
  Prediction time: 0.0010s

Training SVM (Calibrated)...
  Accuracy: 0.6843
  Precision: 0.7186
  Recall: 0.7199
  F1-Score: 0.6839
  Training time: 3.59s
  Prediction time: 0.0040s

Training Naive Bayes...
  Accuracy: 0.6290
  Precision: 0.6830
  Recall: 0.6877
  F1-Score: 0.6119
  Training time: 0.02s
  Prediction time: 0.0030s

Training Random Forest...
  Accuracy: 0.7024
  Precision: 0.7581
  Recall: 0.7478
  F1-Score: 0.7081
  Training time: 0.97s
  Prediction time: 0.0640s

Training Hist Gradient Boosting...
  Accuracy: 0.6964
  Precision: 0.7651
  Recall: 0.7493
  F1-Score: 0.7057
  Training time: 2.57s
  Prediction time: 0.0570s

Training SVM+HGB Ensemble...
  Accuracy: 0.6954
  Precision: 0.7413
  Recall: 0.7395
  F1-Score: 0.6989
  Training time: 5.06s
  Prediction time: 0.0640s

Training AdaBoost...
  Accuracy: 0.6722
  Precision: 0.7310
  Recall: 0.7103
  F1-Score: 0.6757
  Training time: 3.61s
  Prediction time: 0.0260s

Training XGBoost...
  Accuracy: 0.7066
  Precision: 0.7647
  Recall: 0.7514
  F1-Score: 0.7121
  Training time: 1.57s
  Prediction time: 0.0100s

=== MODEL COMPARISON SUMMARY ===
                 Model  Accuracy  Precision   Recall  F1-Score  Train Time (s)  Pred Time (s)
         Decision Tree  0.675718   0.744081 0.722065  0.682840        0.391093       0.001000
                   SVM  0.670232   0.712114 0.720503  0.673178        2.077413       0.001000
      SVM (Calibrated)  0.684312   0.718593 0.719856  0.683902        3.585919       0.004000
           Naive Bayes  0.629000   0.682991 0.687693  0.611916        0.015000       0.003000
         Random Forest  0.702414   0.758128 0.747807  0.708081        0.972231       0.063999
Hist Gradient Boosting  0.696380   0.765056 0.749276  0.705706        2.570420       0.057000
      SVM+HGB Ensemble  0.695374   0.741264 0.739502  0.698866        5.058023       0.063999
              AdaBoost  0.672244   0.731034 0.710325  0.675724        3.607850       0.026000
               XGBoost  0.706619   0.764723 0.751413  0.712074        1.571548       0.009999

Best model (by macro F1-Score): XGBoost

[OK] Task 6 Complete: Classical ML modeling finished

============================================================
TASK 7: Advanced Evaluation
============================================================

Number of unique participants: 12
Participants: ['Cycling-2023-09-14_06-22-31' 'Cycling-2023-09-14_06-33-47'
 'Cycling-2023-09-14_06-47-00' 'Cycling-2023-09-16_07-43-07'
 'Cycling-2023-09-16_09-25-09' 'Cycling-2023-10-18_06-36-17'
 'Cycling-2023-10-18_06-51-26' 'Sitting-2023-09-14_08-37-45'
 'Sitting-2023-09-14_09-11-15' 'Sitting-2023-10-18_09-05-37'
 'Walking-2023-09-14_21-51-59' 'Walking-2023-09-16_18-14-40']
Using scikit-learn XGBClassifier
Running LOSO evaluation (may take a while)...

Fold 1/12 (Participant Cycling-2023-09-14_06-22-31): Accuracy = 0.9357
Fold 2/12 (Participant Cycling-2023-09-14_06-33-47): Accuracy = 0.9317
Fold 3/12 (Participant Cycling-2023-09-14_06-47-00): Accuracy = 0.9841
Fold 4/12 (Participant Cycling-2023-09-16_07-43-07): Accuracy = 0.9129
Fold 5/12 (Participant Cycling-2023-09-16_09-25-09): Accuracy = 0.9778
Fold 6/12 (Participant Cycling-2023-10-18_06-36-17): Accuracy = 0.9542
Fold 7/12 (Participant Cycling-2023-10-18_06-51-26): Accuracy = 0.9494
Fold 8/12 (Participant Sitting-2023-09-14_08-37-45): Accuracy = 0.6240
Fold 9/12 (Participant Sitting-2023-09-14_09-11-15): Accuracy = 0.5774
Fold 10/12 (Participant Sitting-2023-10-18_09-05-37): Accuracy = 0.6932
Fold 11/12 (Participant Walking-2023-09-14_21-51-59): Accuracy = 0.6282
Fold 12/12 (Participant Walking-2023-09-16_18-14-40): Accuracy = 0.4099

=== LOSO OVERALL RESULTS ===
Mean Accuracy: 0.7982 (+/- 0.1901)
Overall Accuracy: 0.7832
Overall Precision (macro): 0.8059
Overall Recall (macro): 0.6724
Overall F1-Score (macro): 0.7143

=== EVALUATION METHOD COMPARISON ===
     Evaluation Method  Accuracy  Precision (macro)  Recall (macro)  F1-Score (macro)
Standard Split (80/20)  0.706619           0.764723        0.751413          0.712074
 LOSO Cross-Validation  0.783170           0.805914        0.672424          0.714274
Testing window size: 25 samples (0.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6580, F1: 0.6663, N=684178

Testing window size: 50 samples (1.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6749, F1: 0.6805, N=328375

Testing window size: 75 samples (1.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6839, F1: 0.6907, N=221854

Testing window size: 100 samples (2.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6851, F1: 0.6926, N=164167

Testing window size: 125 samples (2.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6791, F1: 0.6878, N=132376

Testing window size: 150 samples (3.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6895, F1: 0.6950, N=109423

Testing window size: 175 samples (3.50 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6910, F1: 0.6956, N=94327

Testing window size: 200 samples (4.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6947, F1: 0.6998, N=82063

Testing window size: 250 samples (5.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.6983, F1: 0.7022, N=65632

Testing window size: 300 samples (6.00 seconds)
Using multiprocessing with 31 workers for feature extraction...
  Processed 10/35 sensor groups...
  Processed 20/35 sensor groups...
  Processed 30/35 sensor groups...
  Processed 35/35 sensor groups...

  Completed processing all 35 sensor groups
  Accuracy: 0.8385, F1: 0.7924, N=54688


=== WINDOW SIZE COMPARISON TABLE ===
 Window Size  Duration (s)  N Samples  Accuracy  Precision   Recall  F1-Score
          25           0.5     684178  0.657977   0.715574 0.694548  0.666296
          50           1.0     328375  0.674884   0.729156 0.710032  0.680529
          75           1.5     221854  0.683870   0.738934 0.721697  0.690693
         100           2.0     164167  0.685083   0.743122 0.723521  0.692551
         125           2.5     132376  0.679106   0.740861 0.720154  0.687805
         150           3.0     109423  0.689468   0.748568 0.726880  0.695029
         175           3.5      94327  0.690978   0.743972 0.729112  0.695629
         200           4.0      82063  0.694693   0.747247 0.732897  0.699846
         250           5.0      65632  0.698256   0.750269 0.735359  0.702187
         300           6.0      54688  0.838545   0.878841 0.748034  0.792356

=== PER-CLASS PERFORMANCE REPORT ===
              precision    recall  f1-score   support

     cycling       0.97      0.63      0.76      6649
     sitting       0.89      0.70      0.78      1890
     walking       0.43      0.93      0.59      2399

    accuracy                           0.71     10938
   macro avg       0.76      0.75      0.71     10938
weighted avg       0.84      0.71      0.73     10938


Most common classification errors (true -> predicted):
  true=cycling, predicted=walking: 2365 times
  true=sitting, predicted=walking: 555 times
  true=walking, predicted=cycling: 113 times
  true=cycling, predicted=sitting: 97 times
  true=walking, predicted=sitting: 63 times
  true=sitting, predicted=cycling: 16 times

[OK] Task 7 Complete: Advanced evaluation finished

============================================================
ALL TASKS COMPLETE!
============================================================

Visualizations saved to: visualizations

Generated files:
  - task1_dataset_exploration.png
  - task2_annotated_signals.png
  - task3_preprocessing_comparison.png
  - task4_windowing_strategies.png
  - task5_feature_distributions.png
  - task5_feature_importance.png
  - task6_model_comparison.png
  - task7_evaluation_comparison.png
  - task7_window_size_comparison.png
  - task7_confusion_matrix.png
  - task7_error_analysis.png
  - data/processed/X_seq_train.npy, data/processed/X_seq_test.npy (sequence data for deep activity classification models)
  - data/processed/y_seq_train.npy, data/processed/y_seq_test.npy (sequence labels for activity classification)
  - console_output_20251117_231050.txt (console output log)
============================================================
